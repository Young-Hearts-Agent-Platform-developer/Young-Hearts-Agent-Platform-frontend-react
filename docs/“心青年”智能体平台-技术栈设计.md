# “心青年”智能体平台 技术栈设计文档

## 版本记录
| 日期 | 变更内容 | 关联功能文档 |
|---|---|---|
| 2025-12-27 | 初始版本创建（MVP 聚焦基础检索与工单） | `docs/归档/2025-12-27-“心青年”智能体平台-功能文档.md` |
| 2026-01-11 | **架构升级**：<br>1. RAG 提升为 MVP 核心，引入向量库与编排框架；<br>2. 适配“统一服务中心”和细粒度 RBAC 权限体系；<br>3. 增加志愿者排班与专家审核的技术支撑。 | `docs/“心青年”智能体平台-功能文档.md` |

## 1. 技术栈概览

| 技术维度 | 选用技术 | 核心作用 | 变更状态 |
|---|---|---|---|
| **前端框架** | `React` + `Vite` + `Ant Design` | 管理后台与用户端界面（PC/H5响应式），组件丰富。 | 无变更 |
| **后端框架** | `Python` + `FastAPI` | 高性能 API 服务，利用 Pydantic 进行严格的数据校验与文档自动生成。 | 无变更 |
| **数据库** | `MySQL` (v8.0+) | 存储用户、工单、志愿活动、排班、知识库元数据等结构化关系数据。 | 无变更 |
| **向量存储** | **`ChromaDB`** (或 `Qdrant`) | **新增** (原计划为二期)。<br>存储知识库文本的向量索引，支撑 RAG 语义检索。ChromaDB 轻量且对 Python 友好；Qdrant 性能强，均支持 Docker。 | **升级** |
| **LLM 编排** | **`LangChain`** (Python版) | **新增**。<br>封装 RAG 流程（文档切片、嵌入、检索、上下文构建），降低开发复杂度。 | **新增** |
| **模型服务** | OpenAI 兼容 API | 接入 DeepSeek/Moonshot 等高性价比国产大模型，兼顾成本与中文能力。 | **明确** |
| **缓存/队列** | `Redis` + `Celery` | 缓存热点数据；处理邮件发送、文档异步切片等耗时任务。 | 无变更 |
| **身份认证** | `JWT` + `RBAC` (FastAPI Deps) | 实现五级角色（家属/志愿者/专家/管理员/运维）的精细化鉴权。 | **强化** |
| **部署容器** | `Docker` + `docker-compose` | 统一开发与部署环境，一键拉起 Database, Retina, Backend, Frontend。 | 无变更 |

## 2. 核心功能实现（本次重点）

### 2.1 RAG 智能咨询引擎（核心 MVP）
*   **技术支撑**：`FastAPI` + `LangChain` + `ChromaDB` + `Embedding Model` (如 BGE-M3 或 OpenAI Embedding)
*   **实现方案**：
    1.  **数据入库流**：后台上传 PDF/MD -> Celery 异步任务 -> `LangChain` 文本分割 (Text Splitter) -> 调用 Embedding API -> 存入 `ChromaDB` (Metadata 包含 source_id, page)。
    2.  **检索问答流**：用户提问 -> 生成 Query Vector -> 在 `ChromaDB` 检索 Top-K 相关片段 -> 组装 Prompt (包含 System Prompt 约束) -> 调用 LLM 生成回答。
    3.  **兜底机制**：若检索到的片段相似度低于阈值（如 0.6），通过逻辑分支直接返回“暂无相关信息，建议转人工”，不调用生成大模型以防幻觉。

### 2.2 统一服务中心与 RBAC 权限
*   **技术支撑**：`FastAPI Middleware` + `Pydantic Models`
*   **实现方案**：
    1.  **权限控制**：在 FastAPI `Depends` 中实现 `get_current_active_user` 和 `check_role(['admin', 'expert'])`。
    2.  **数据隔离**：
        *   **接口层**：不同角色复用同一查询接口（如 `GET /tickets`），但 Service 层根据 current_user 角色自动注入过滤条件（志愿者只能看自己认领的，专家可看所有待处理的）。
        *   **响应层**：定义多套 Pydantic Schema（如 `UserPublic`, `UserInternal`），在序列化时严格剔除 `mobile` 等敏感字段，仅管理员可见完整信息。

### 2.3 志愿者与专家协同模块
*   **技术支撑**：`MySQL` (复杂关系) + `Redis` (状态)
*   **数据模型变更**：
    *   `users` 表：扩展 `role` (enum), `is_verified`, `is_public_visible`, `public_email`。
    *   `expert_profiles` / `volunteer_profiles`：存储资质、擅长领域、服务时长等。
    *   `offline_shifts` (排班表)：字段包含 `activity_id`, `start_time`, `end_time`, `max_participants`, `current_participants`。
    *   `shift_applications` (报名记录)：关联 `user_id` 与 `shift_id`，包含状态 `audit_status`。
*   **业务逻辑**：
    *   **状态机管理**：志愿者服务状态（Online/Busy/Offline）存放在 Redis 中以便实时查询与派单，持久化记录定期写入 MySQL。
    *   **通知系统**：利用 `Celery` 监听特定事件（如“班次开始前24小时”、“工单被指派”），触发邮件发送。

### 2.4 知识库可视化（查阅模式）
*   **技术支撑**：`MySQL Fulltext` (或延续之前的 SQLite FTS 方案)
*   **实现方案**：
    *   为满足家属的主动查询需求，RAG 的向量库不适合直接做“关键词列表展示”。
    *   因此，知识条目需 **双写**：一份切片入向量库（供 AI 读），一份结构化存 MySQL（供人读）。
    *   查阅界面使用 SQL `LIKE` 或 MySQL 内置全文索引实现传统搜索。

## 3. 架构设计图（文字描述）

1.  **接入层**：Nginx (反向代理/静态文件服务) -> 对外暴露 HTTP/HTTPS。
2.  **应用层**：
    *   **Backend** (FastAPI): 处理 API 请求，鉴权，业务逻辑。
    *   **Worker** (Celery): 处理文档解析、向量化、邮件发送。
3.  **数据层**：
    *   **MySQL**: 核心业务数据（用户、工单、知识库元数据）。
    *   **ChromaDB**: 向量数据（知识库Embedding）。
    *   **Redis**: 缓存、Celery Broker、用户实时状态。
4.  **外部服务**：
    *   **LLM API**: 智谱/DeepSeek/OpenAI。
    *   **Email SMTP**: 邮件通知。

## 4. 潜在风险与替代

| 风险点 | 风险描述 | 应对/替代方案 |
|---|---|---|
| **RAG 准确性** | 学生团队对 Prompt Engineering 和切片策略经验不足，可能导致检索不准。 | 1. 引入 LangChain 预置的高级检索策略（如 Parent Document Retriever）。<br>2. 增加“专家审核”环节，不准的切片人工修正 Metadata。 |
| **部署资源限制** | 向量数据库和 LLM API 成本可能超出预期。 | 1. 向量库选型 `ChromaDB` 或 `FAISS`，纯文件/内存运行，零成本。<br>2. LLM 模型选用按 Token 计费且价格低廉的国产模型（如 DeepSeek-V3）。 |
| **开发复杂度** | RBAC 权限逻辑交织，代码容易变得混乱。 | 在后端强制分离 `Router` (路由) / `Service` (业务) / `CRUD` (数据) 层，权限检查统一在 Router 层完成。 |

---
**提醒**：由于 RAG 变为核心，建议开发团队优先跑通 "LangChain + ChromaDB + API" 的最小闭环 Demo，并在 `.env` 中配置好 LLM API Key。
