# 完善 SSE 对话流式输出 研究报告

## 版本记录

| 日期 | 版本 | 修改内容 | 修改原因 |
|---|---|---|---|
| 2026-01-28 | v1.0 | 初始设计 | 建立任务，分析现状与优化方向 |

## 研究问题

如何完善并优化目前 `consult` 模块基于 SSE 的 AI 对话流式输出，特别是支持引用源（Sources）和快捷操作（Quick Actions）等结构化数据的解析与渲染，以及增强流式处理的健壮性。

## 发现摘要

当前 `chatSSE` 实现采用了非标准的流式处理方式（直接按行解析文本），虽然能支持基本的文本逐字输出和简单的 Topic 更新，但缺乏对结构化数据（如引用来源、建议追问）的支持。UI 层虽然预留了渲染 `sources` and `quickActions` 的逻辑，但数据流处理层并未对接这些字段。建议重构 SSE 解析逻辑，采用更标准的 `key: value` 解析或特定的 JSON 块解析策略。

## 相关文件清单

|文件路径|作用说明|关键行号|
|---|---|---|
|src/api/consult.js|SSE 请求与流式解析实现|L42-L110|
|src/pages/consultation/chat.jsx|聊天页面 UI，消息状态管理|L108-L170|
|src/types/ChatRequest.d.ts|Chat 请求与响应类型定义|L1-L10|

## 当前实现分析

### 1. API 层 (`src/api/consult.js`)

目前 `chatSSE` 使用 `fetch` 获取 `ReadableStream`，并使用 `TextDecoder` 解码。

```javascript
// src/api/consult.js L91-L100
// 简单的按行分割
let lines = buffer.split(/(\r?\n)/);
// ...
function handleLine(line) {
  // 特殊标记处理
  if (line.startsWith('[ERROR]')) { ... }
  if (line.startsWith('[TOPIC]')) { ... }
  if (line === '[DONE]') { ... }
  // 默认作为文本内容
  if (onMessage) onMessage(line, {});
}
```

**问题点**：
- **非标准 SSE 解析**：未处理 `data: ` 前缀，假设每一行都是有效负载，可能导致协议兼容性问题。
- **缺乏结构化支持**：无法区分当前行是“文本内容”、“引用源”还是“建议动作”。所有非特殊标记的内容都被视为对话文本拼接。
- **Buffer 处理**：`split(/(\r?\n)/)` 的逻辑在边界加 chunks 拼接时可能存在 bug（如一个多字节字符被截断，或者换行符被分割在两个 chunk 中）。

### 2. UI 层 (`src/pages/consultation/chat.jsx`)

```javascript
// src/pages/consultation/chat.jsx L159-L163
onMessage: (delta, meta) => {
  if (meta && meta.isTopic) {
    setSessionTitle(id, delta && delta.trim() ? delta : '新对话');
  }
  // 仅简单的文本拼接
  aiMsgRef.current = { ...aiMsgRef.current, content: (aiMsgRef.current?.content || "") + (delta || "") };
  setPendingDelta(delta || "");
},
```

**缺口**：
- 即使 API 层解析出了 `sources` 或 `quickActions`，`onMessage` 回调目前只接收 `delta` 字符串和简单的 `meta`，无法更新 `aiMsgRef` 中的其他字段。

## 架构洞察与优化方案

### 方案 1：增强现有自定义协议（低成本）

保持当前的自定义协议，增加新的前缀标记：
- `[SOURCES] [{"id": "1", "title": "..."}]`
- `[ACTIONS] [{"label": "继续", "value": "continue"}]`

**优点**：改动小，向后兼容。
**缺点**：非标准，后端需配合修改格式。

### 方案 2：转向标准 SSE 格式（推荐）

后端返回标准 `text/event-stream`：
```plaintext
event: message
data: {"type": "content", "delta": "你好"}

event: message
data: {"type": "sources", "data": [...]}

event: message
data: {"type": "actions", "data": [...]}
```

或者单一 `data` 结构：
```plaintext
data: {"content": "你好", "sources": null}
```

考虑到目前代码库似乎在控制后端协议（或者是全栈开发），建议采用 **带类型的 JSON Line** 模式或 **标准 SSE 行解析**。

鉴于 `src/api/consult.js` 中已有 `handleLine` 逻辑，且 `docs/openapi.json` (未读取但文件名存在) 可能有定义，我们需要确认后端协议。若无法修改后端，则需适配后端当前的输出格式（需明确后端到底返回什么）。

假设后端目前遵循的是“每行一段文本”的简单流，我们需要在前端扩展解析器以支持可能的 JSON 数据。

### 优化计划

1.  **重构 `chatSSE` 解析器**：引入更健壮的流式解析逻辑（参考 `event-source-polyfill` 或 `fetch-event-source` 的实现思路，处理缓冲区拼接）。
2.  **扩展协议支持**：
    *   在 `handleLine` 中增加对 `JSON` 对象的尝试解析（如果行首是 `{`），或者定义新的标记。
    *   或者，如果后端已经支持标准 SSE（`data: ...`），则改为解析该格式。
3.  **UI 状态更新优化**：
    *   修改 `onMessage` 签名，使其支持传递 `sources` 和 `actions`。
    *   更新 `aiMsgRef.current` 时合并这些新字段。

### 补充发现 (OpenAPI 分析)

检查 `openapi.json` 发现：
- `/api/consult/chat` 接口响应 schema 为空 `{}`，未定义具体的 SSE 数据结构，验证了后端协议的不确定性。
- `ConsultationMessage` 对象包含 `sources` 字段 (`anyOf: [{}, null]`)，证实了后端数据模型支持引用源，前端需要确保 SSE 处理能正确解析并填充该字段。

## 潜在风险

- **后端协议不确定性**：如果不清楚后端实际返回的数据格式，贸然修改解析逻辑会导致乱码。需要先确认后端协议（通过测试或文档）。
- **性能影响**：如果流式传输大量 JSON 数据（如大段引用），可能会造成主线程解析卡顿，需注意 JSON.parse 的频率。

## 开放问题

1.  后端是否已经支持返回引用源和快捷操作？是以什么格式返回的？
2.  目前的 buffer 拼接逻辑是否在经过边界测试（如 emoji 分割、CRLF 分割）？

## 参考资料

- [Server-Sent Events 规范](https://html.spec.whatwg.org/multipage/server-sent-events.html)
